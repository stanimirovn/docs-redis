---
title: Installing and Upgrading Redis for PCF
owner: London Services
---

## <a id="install"></a>Installation Steps

To add Redis for PCF to Ops Manager, follow the procedure for adding Pivotal Ops Manager tiles:

1. Download the product file from [Pivotal Network](https://network.pivotal.io/products/p-redis).
1. Upload the product file to your Ops Manager installation.
1. Click **Add** next to the uploaded product description in the Available Products view to add this product to your staging area.
1. (Optional) Click the newly added tile to configure your [possible service plans](#configuration), [syslog draining](#syslog), and [backups](#backup).
1. Click **Apply Changes** to install the service.

After installing, be sure to:

+ Monitor the health and performance of your Redis instances by setting up [logging] (https://docs.pivotal.io/redis/1-7/installing.html#syslog) and [tracking metrics] (https://docs.pivotal.io/redis/1-7/monitoring.html).
+ Configure [automatic backups] (https://docs.pivotal.io/redis/1-7/installing.html#backup).

## <a id="configuration"></a>Configuring PCF Redis

###  <a id="service-plans"></a>Configure Redis Service Plans

Select the **Redis** tile from the Installation Dashboard to display the configuration page and allocate resources to Redis service plans.

###  <a id="shared-vm-config"></a>Shared-VM Plan

1.  Select the **Shared-VM Plan** tab.
![shared vm config](shared-vm-config.png)

1.  Configure these fields:<br><br>
      * **Redis Instance Memory Limit**---Maximum memory used by a shared-VM instance
      * **Redis Service Instance Limit**---Maximum number of shared-VM instances

 	Memory and instance limits depend on the total system memory of your Redis broker VM and require some
 	additional calculation. For more information, see [Memory Limits for Shared-VM Plans](#shared-vm-memory-limits) below.  

1. Click **Save**.

1. If you do not want to use the on-demand service, you must make all of the on-demand service plans inactive. 
Click the tab for each on-demand plan, and select **Plan Inactive**.
See the example in Step 4 of [Removing On-Demand Service Plans](#remove-on-demand) above.

1. To change the allocation of resources for the Redis broker, click the **Resource Config** tab.
    <br><br>The Redis broker server runs all of the Redis instances for your Shared-VM plan. 
    From the **Resource Config** page, you can change the CPU, RAM, Ephemeral Disk, and Persistent Disk made available, as needed.

#### <a id="shared-vm-memory-limits"></a>Memory Limits for Shared-VM Plans
Additional calculation is required to configure memory limits for shared-VM plans. 
With these plans, several service instances share the VM, and the Redis broker also runs on this same VM. 
Therefore, the memory used by all the shared-vm instances combined should be at most 45% of the memory of the Redis broker VM.

To configure the limits in these fields, 
estimate the maximum memory that could be used by all your Redis shared-VM instances combined. 
If that figure is higher than 45% of the Redis broker 
VM's total system memory, you can do one of the following:

  + Decrease the **Redis Instance Memory Limit**.
  + Decrease the number of instances in **Redis Service Instance Limit**.
  + Increase the RAM for the Redis Broker in the **Resource Config** tab as shown below.

    <img src="./images/redis-broker-resource.png">

  Here are some examples for setting these limits:

  <table border="1" class="nice">
      <tr>
        <th>Redis Broker VM Total Memory</th>
        <th>Redis Instance Memory Limit</th>
        <th>Redis Service Instance Limit</th>
      </tr>
      <tr>
        <td>16&nbsp;GB</td>
        <td>512&nbsp;MB</td>
        <td>14</td>
      </tr>
      <tr>
        <td>16&nbsp;GB</td>
        <td>256&nbsp;MB</td>
        <td>28</td>
      </tr>
      <tr>
        <td>64&nbsp;GB</td>
        <td>512&nbsp;MB</td>
        <td>56</td>
      </tr>
  </table>

  <p class="note"><strong>Note</strong>: It is possible to configure a larger <strong>Redis Service Instance Limit</strong>, 
      if you are confident that the majority of the deployed instances will not use a large amount of their allocated memory, 
      for example in development or test environments. <br><br>However, this practice is not supported and can cause your server to run out of memory,
      preventing users from writing any more data to any Redis shared-VM instance.
  </p>

###  <a id="dedicated-vm-config"></a>Dedicated-VM Plan

1. Select the **Resource Config** tab to change the allocation of resources for the Dedicated Node.
![dedicated vm config](dedicated-vm-config.png)

  - The default configuration creates five dedicated nodes (VMs). 
  Each node can run one Redis dedicated-VM instance.
  - You can change the number of dedicated nodes, and configure the size of the 
  persistent and ephemeral disks, and the CPU and RAM for each node.
  - The default VM size is small. It is important that you set the correct 
  VM size to handle anticipated loads. 
  - With dedicated-VM plans, there is one Redis service instance on each VM. 
  The maximum memory an instance can use should be at most 45% of the total system RAM on the VM.
  You can set this with the `maxmemory` configuration. 
  The app can use 100% of `maxmemory`--that is, up to 45% of the system RAM.
  - Pivotal recommends the persistent disk be set to 3.5x the amount of system RAM.
1. Click **Save**.  

### <a id="resources"></a>Configure Resources for Dedicated-VM and Shared-VM Plans

To configure resources for the Shared-VM and Dedicated-VM plans, click the **Resource Config** settings tab on the Redis for PCF tile.

* The Shared-VM plan is on the **Redis Broker** resource.
* The Dedicated-VM plan is on the **Dedicated Node** resource.

The following are the default resource and IP requirements for Redis for PCF when using the Shared-VM or Dedicated-VM plans:
<table border="1" class="nice">
  <tr>
    <th>Product</th>
    <th>Resource</th>
    <th>Instances</th>
    <th>CPU</th>
    <th>Ram</th>
    <th>Ephemeral</th>
    <th>Persistent</th>
    <th>Static IP</th>
    <th>Dynamic IP</th>
  </tr>
  <tr>
    <td>Redis</td>
    <td>Redis Broker</td>
    <td>1</td>
    <td>2</td>
    <td>3072</td>
    <td>4096</td>
    <td>9216</td>
    <td>1</td>
    <td>0</td>
  </tr>
  <tr>
    <td>Redis</td>
    <td>Dedicated Node</td>
    <td>5</td>
    <td>2</td>
    <td>1024</td>
    <td>4096</td>
    <td>4096</td>
    <td>1</td>
    <td>0</td>
  </tr>
  <tr>
    <td>Redis</td>
    <td>Broker Registrar</td>
    <td>1</td>
    <td>1</td>
    <td>1024</td>
    <td>2048</td>
    <td>0</td>
    <td>0</td>
    <td>1</td>
  </tr>
  <tr>
    <td>Redis</td>
    <td>Broker De-Registrar</td>
    <td>1</td>
    <td>1</td>
    <td>1024</td>
    <td>2048</td>
    <td>0</td>
    <td>0</td>
    <td>1</td>
  </tr>
  <tr>
    <td>Redis</td>
    <td>Compliation</td>
    <td>2</td>
    <td>2</td>
    <td>1024</td>
    <td>4096</td>
    <td>0</td>
    <td>0</td>
    <td>1</td>
  </tr>
</table>

### <a id="disable-shared-dedicated"></a>Disable Shared and Dedicated VM Plans

You can disable Shared and Dedicated VM Plans by doing the following while configuring Redis tile:

1. Ensure at least one On-Demand plan is active.

1. Configure the following tabs:<br><br>
  * **Shared-VM Plan**:<br>
    a. Set **Redis Service Instance Limit** to 0.<br>
    b. Click **Save**.<br><br>
  * **Errands**:<br>
    a. Set **Broker Registrar** to Off.<br>
    b. Set **Smoke Tests** to Off.<br>
    c. Set **Broker Deregistrar** to Off.<br>
    d. Leave all four On-Demand errands On. <br>
    e. Click **Save**.<br><br>
  * **Resource Config**:<br>
    a. Decrease **Redis Broker** Persistent disk type to the smallest size available.<br>
    b. Decrease **Redis Broker** VM type to the smallest size available.<br>
    c. Set **Dedicated Node** Instances to 0.<br>
    d. Click **Save**.<br>

##  <a id="securecomms"></a>Configuring Secure Communication
Redis for PCF v1.7.2 lets the operator turn on/off TLS communications for metrics, via a `Use non-secure communication for metrics` checkbox on the metrics configuration
page in Ops Manager. Configure this checkbox for different versions of PCF as follows:

* **PCF v1.8**: Select this checkbox to send metrics to the Firehose.

* **PCF v1.9**: Clear this checkbox to send metrics to the Firehose securely, or select it to send metrics insecurely.

* **PCF v1.10 and later**: Clear this checkbox to send metrics to the Firehose and avoid errors.

![Configuring Secure Metrics](Enable-TLS.png)

Setting this checkbox incorrectly can cause a `Cannot generate manifest... unknown property "cf_etcd_client_cert"` error:

![Configuring Secure Metrics error](TLS-error.png)

### <a id="syslog"></a>Configure Syslog Output

Pivotal recommends that operators configure a syslog output.

1.  Add the Syslog address, Syslog port and transport protocol of your log management tool.

    The information required for these fields is provided by your log management tool.

    ![syslog configuration](syslog-forwarding.png)

1.  Click **Save**.

### <a id="backup"></a>Creating Backups of Redis Instances

You can configure backups to be run for all instances, across both service plans.

The key features are:

* Runs on a configurable schedule
* Every instance is backed up, across both service plans
* The Redis broker statefile is backed up
* For each backup artefact, a file is created that contains the MD5 checksum for that artifact. This can be used to validate that the artefact is not corrupted.
* You can configure AWS S3, SCP, Azure or Google Cloud Storage as your destination
* Data from Redis is flushed to disk, before the backup is started by running a `BGSAVE` on each instance
* Backups are labelled with timestamp, instance GUID and plan name

#### Configuration
To enable backups, you will first need to choose your backup destination type - AWS S3, SCP, Azure or Google Cloud Storage.

Click on the tile in OpsManager, followed by the `Backups` link on the left hand menu.
![OpsManager Backups view](redis-backup.png)

##### S3 backup fields
![OpsManager Backups S3 view](s3backupoptions.png)

| Field             | Description                                                                                                                                                                                                                                                                                                                                                                                            | Mandatory/Optional                                               |
|-------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------|
| Access Key ID     | The access key for your S3 account                                                                                                                                                                                                                                                                                                                                                                     | Mandatory                                                        |
| Secret Access Key | The Secret Key associated with your Access Key                                                                                                                                                                                                                                                                                                                                                         | Mandatory                                                        |
| Endpoint URL      | The endpoint of your S3 account, e.g. `http://s3.amazonaws.com`                                                                                                                                                                                                                                                                                                                                        | Optional, defaults to `http://s3.amazonaws.com` if not specified |
| Bucket Name       | Name of the bucket you wish the files to be stored in.                                                                                                                                                                                                                                                                                                                                                 | Mandatory                                                        |
| Path              | Path inside the bucket to save backups to.                                                                                                                                                                                                                                                                                                                                                             | Mandatory                                                        |
| Backup timeout    | The amount of time, in seconds, that the backup process will wait for the BGSAVE command to complete on your instance, before transferring the RDB file to your configured destination                                                                                                                                                                                                                 | Mandatory                                                        |
| Cron Schedule     | Backups schedule in crontab format.  For example, once daily at 2am is `* 2 * * *`.  Also accepts a pre-defined schedule: any of `@yearly`, `@monthly`, `@weekly`, `@daily`, `@hourly`, or `@every <time>`, where `<time>` is any supported time string (e.g. `1h30m`). For more information, see [the cron package documentation](https://godoc.org/github.com/robfig/cron#hdr-Predefined_schedules). | Mandatory                                                        |

##### AWS IAM Policy
An AWS IAM policy describes the permissions related to your bucket.
The minimum set of policies required in order to upload the backup files are:

```
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "s3:ListBucket",
                "s3:ListBucketMultipartUploads",
                "s3:ListMultipartUploadParts",
                "s3:PutObject"
            ],
            "Resource": [
                "arn:aws:s3:::<bucket-name>",
                "arn:aws:s3:::<bucket-name>/*"
            ]
        }
    ]
}
```
Notes:

* Make sure to replace `<bucket-name>` with your correct values.
* `s3:CreateBucket` is only required if the S3 bucket does not exist.
* The additional `s3:CreateBucket` action is also required if the S3 bucket does not exist.


##### SCP backup fields
![OpsManager Backups SCP view](scpbackupoptions.png)

| Field                 | Description                                                                                                                                                               | Mandatory/Optional |
|-----------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------|
| Username              | The username to use for transferring backups to the scp server                                                                                                            | Mandatory          |
| Private Key           | The private ssh key of the user configured in `Username`                                                                                                                  | Mandatory          |
| Hostname              | The hostname or IP address of the SCP server                                                                                                                              | Mandatory          |
| Destination Directory | The path in the scp server, where the backups will be transferred                                                                                                         | Mandatory          |
| SCP Port              | The scp port of the scp server                                                                                                                                            | Mandatory          |
| Cron Schedule         | Backups schedule in crontab format. Refer to table for S3 backups for details                                                                                             | Mandatory          |
| Backup timeout        | The amount of time, in seconds, that the backup process will wait for the BGSAVE command to complete on your instance, before transferring the RDB file to the scp server | Mandatory          |

##### GCS backup fields
![OpsManager Backups GCS view](gcsbackupoptions.png)

PCF Redis uses service account credentials to upload backups to Google Cloud Storage. The service account should have `Storage Admin` permissions. Please refer to the [documentation](https://cloud.google.com/storage/docs/authentication#service_accounts) for details on how to set up a GCP service account.

| Field                       | Description                                                                                                                                                                                                                                                                                      | Mandatory/Optional |
|-----------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------|
| Project ID                  | GCP Project ID                                                                                                                                                                                                                                                                                   | Mandatory          |
| Bucket name                 | Name of the bucket you wish the files to be stored in.                                                                                                                                                                                                                                           | Mandatory          |
| Service account private key | The JSON Secret Key associated with your Service Account. See [documentation](https://cloud.google.com/storage/docs/authentication#generating-a-private-key) for details on how to set up service account keys.                                                                                  | Mandatory          |
| Cron Schedule               | Backups schedule in crontab format. For example, once daily at 2am is * 2 * * *. Also accepts a pre-defined schedule: any of @yearly, @monthly, @weekly, @daily, @hourly, or @every , where is any supported time string (e.g. 1h30m). For more information, see the cron package documentation. | Mandatory          |
| Backup timeout              | The amount of time, in seconds, that the backup process will wait for the BGSAVE command to complete on your instance, before transferring the RDB file to your configured destination                                                                                                           | Mandatory          |


##### Azure backup fields
![OpsManager Backups Azure view](azurebackupoptions.png)

| Field                    | Description                                                                                                                                                                                                                                                                                      | Mandatory/Optional |
|--------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------|
| Account                  | Account name                                                                                                                                                                                                                                                                                     | Mandatory          |
| Azure Storage Access Key | Azure specific credentials required to write to the Azure container                                                                                                                                                                                                                              | Mandatory          |
| Container name           | Name of the Azure container which will store backup files.                                                                                                                                                                                                                                       | Mandatory          |
| Destination Directory    | Directory where the backup files will be stored within the Azure container.                                                                                                                                                                                                                      | Mandatory          |
| Blob Store Base URL      | URL pointing to Azure resource                                                                                                                                                                                                                                                                   | Optional           |
| Cron Schedule            | Backups schedule in crontab format. For example, once daily at 2am is * 2 * * *. Also accepts a pre-defined schedule: any of @yearly, @monthly, @weekly, @daily, @hourly, or @every , where is any supported time string (e.g. 1h30m). For more information, see the cron package documentation. | Mandatory          |
| Backup timeout           | The amount of time, in seconds, that the backup process will wait for the BGSAVE command to complete on your instance, before transferring the RDB file to your configured destination                                                                                                           | Mandatory          |


For each backup destination, the field `Backup timeout` causes backups to fail after a configured timeout. 
Redis' BGSAVE will continue, but backups will not be uploaded to destinatons if this timeout is reached.


### <a id="azs"></a>Networks, Security, and Assigning AZs

####  <a id="network-configuration"></a>Network Configuration

The following ports and ranges are used in this service:

| Port                  | Protocol                     | Direction and Network                                                                          | Reason                                                                                                                      |
|:----------------------|:-----------------------------|:-----------------------------------------------------------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------|
| 8300<br>8301             | tcp<br>tcp and udp | Inbound to CloudFoundry network, outbound from service broker and service instance networks* | Communication between the CF consul\_server and consul\_agents on Redis deployment; used for metrics                         |
| 4001                  | tcp                          | Inbound to CloudFoundry network, outbound from service broker and service instance networks* | Used by the Redis metron_agent to forward metrics to the CloudFoundry etcd server                                          |
| 80                 | tcp                          | Outbound from CloudFoundry to the cf-redis-broker service broker network                       | (Only if using a cf-redis-broker) Access to the cf-redis-broker from the cloud controllers.                                 |
| 6379                  | tcp                          | Outbound from CloudFoundry to any service instance networks      | Access to all nodes from the Diego Cell and Diego Brain network(s)                            |
| 32768-61000           | tcp                          | Outbound from CloudFoundry to the cf-redis-broker service broker network                       | From the Diego Cell and Diego Brain network(s) to the service broker VM. This is only required for the shared service plan. |
| 80 or 443<br>(Typically) | http or https<br>respectively  | Outbound from any service instance networks                                                    | Access to the backup blobstore                                                                                             |

\* Typically the service broker network and service instance network(s) are the same.

####  <a id="asg"></a> Application Security Groups###

To allow this service to have network access you must create [Application Security Groups (ASGs)](http://docs.pivotal.io/pivotalcf/1-7/adminguide/app-sec-groups.html). Ensure your security group allows access to the Redis Service Broker VM and Dedicated VMs configured in your deployment. You can obtain the IP addresses for these VMs in Ops Manager under the <strong>Resource Config</strong> section for the Redis tile.</p>

<p class="note"><strong>Note</strong>: Without ASGs, this service is unusable.</p>

##### Application Container Network Connections

Application containers that use instances of the Redis service require the following outbound network connections:

<table><thead>
<tr>
<th>Destination</th>
<th>Ports</th>
<th>Protocol</th>
<th>Reason</th>
</tr>
</thead><tbody>
<tr>
<td><code>ASSIGNED_NETWORK</code></td>
<td>32768-61000</td>
<td>tcp</td>
<td>Enable application to access shared vm service instance</td>
</tr>
<tr>
<td><code>ASSIGNED_NETWORK</code></td>
<td>6379</td>
<td>tcp</td>
<td>Enable application to access dedicated vm service instance</td>
</tr>
</tbody></table>

Create an ASG called `redis-app-containers` with the above configuration and bind it to the appropriate space or, to give all started apps access, bind to the `default-running` ASG set and restart your apps. Example:

```json
[
  {
    "protocol": "tcp",
    "destination": "ASSIGNED_NETWORK",
    "ports": "6379"
  }
]
```

####  <a id="az-config"></a>Assigning AZs
Assigning multiple AZs to Redis jobs will not guarantee high availability.

All of your Shared-VM instances will run on a single node in just one of the configured availability zones and are therefore not highly availabile.

Each Dedicated-VM instance could be assigned to any of the configured availability zones, however each instance still operates as a single node with no clustering. This separation over availability zones provides no high availability.

![AZ Assignment Diagram](AZ-assignment.png)

## <a id="validation"></a>Validating Installation

### Smoke tests

Smoke tests are run as part of Redis for PCF installation to validate that the install succeeded. Smoke tests are described <a href="/redis/1-6/smoke-tests.html">here</a>.

## <a id="upgrades"></a>Upgrading Redis for PCF

This product enables a reliable upgrade experience between versions of the product that is deployed through Ops Manager.

The upgrade paths are detailed [here](http://docs.pivotal.io/redis/1-6/index.html) for each released version.

To upgrade the product:

* The Operator should download the latest version of the product from [Pivotal Network](https://network.pivotal.io/products/p-redis)
* Upload the new .pivotal file to Ops Manager
* Upload the stemcell associated with the update (*if required*)
* Update any new mandatory configuration parameters (*if required*)
* Press "Apply changes" and the rest of the process is automated

During the upgrade deployment each Redis instance will experience a small period of downtime as each Redis instance is updated with the new software components. This downtime is because the Redis instances are single VMs operating in a non HA setup. The length of the downtime depends on whether there is a stemcell update to replace the operating system image or whether the existing VM can simply have the redis software updated. Stemcells updates incur additional downtime while the IaaS creates the new VM while updates without a stemcell update are faster.

Ops Manager ensures the instances are updated with the new packages and any configuration changes are applied automatically.

Upgrading to a newer version of the product does not cause any loss of data or configuration. This is explicitly tested for during our build and test process for a new release of the product.

### Release policy

When a new version of Redis is released we aim to release a new version of the product containing this soon after.

Where there is a new version of Redis or another dependent software component such as the stemcell released due to a critical CVE, Pivotal's goal is to release a new version of the product within 48 hours.

## <a id="uninstall"></a>Uninstalling Redis for PCF

To uninstall Redis for PCF, click on the trashcan icon in the lower right hand corner of the PCF Redis tile in the PCF Ops Manager Installation dashboard. Confirm deletion of the product and click apply changes.
